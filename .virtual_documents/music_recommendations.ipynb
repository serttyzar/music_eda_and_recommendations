




















import os
import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.io as pio
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.decomposition import PCA

import torch
import torch.nn as nn
import torch.optim as optim

import warnings
warnings.filterwarnings("ignore")











loaded_df = pd.read_csv('data/spotify_songs.csv')


loaded_df.head()











loaded_df.info()





def num_obj_cols(df):
    return df.select_dtypes(['float64', 'int64']).columns.tolist(), df.select_dtypes(exclude=['float64', 'int64']).columns.tolist()
df_num_cols, df_obj_cols = num_obj_cols(loaded_df)

loaded_df[df_num_cols].describe()








loaded_df.isnull().sum()








loaded_df.duplicated().sum()








df = loaded_df.dropna()
df.isna().any().sum()





def convert_dates(date):
    if len(date) == 4:
        return date + '-01-01'
    if len(date) == 7:
        return date + '-01'
    return date

df['track_album_release_date'] = df['track_album_release_date'].apply(convert_dates)
df['year'] = pd.DatetimeIndex(df['track_album_release_date']).year.astype(int)
df['month'] = pd.DatetimeIndex(df['track_album_release_date']).month.astype(int)


df['track_album_release_date'] = pd.to_datetime(df['track_album_release_date'])


df.head(3)





df_num_cols, df_obj_cols = num_obj_cols(df)
df_num_cols, df_obj_cols








music_features = ['danceability', 'energy', 'valence', 'tempo', 
            'duration_ms', 'speechiness', 
            'acousticness', 'loudness', 'instrumentalness', 'liveness']
n_rows = 4
n_cols = 3

fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 24))

sns.set_palette('crest')

for i, feature in enumerate(music_features):
    row = i // n_cols
    col = i % n_cols
    ax = axes[row, col]
    
    sns.histplot(df[feature], kde=True, bins=30, edgecolor='black', alpha=0.7, ax=ax)
    ax.set_title(f'{feature.capitalize()}')
    ax.set_xlabel(feature.capitalize())
    ax.set_ylabel('Frequency')
    ax.grid(axis='y', alpha=0.7)

axes[-1, -1].remove()
axes[-1, -2].remove()

plt.tight_layout()
plt.show()








n_features = len(music_features)
n_cols = 3
n_rows = (n_features + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
fig.suptitle('Distribution of Music Features', fontsize=16)

sns.set_style("whitegrid")
sns.set_palette('crest')

for i, feature in enumerate(music_features):
    row = i // n_cols
    col = i % n_cols
    ax = axes[row, col] if n_rows > 1 else axes[col]
    
    sns.boxplot(x=df[feature], ax=ax)
    ax.set_title(f'{feature.capitalize()}', fontsize=12)
    ax.set_xlabel('')
    ax.tick_params(axis='x', rotation=45)

for i in range(n_features, n_rows * n_cols):
    row = i // n_cols
    col = i % n_cols
    fig.delaxes(axes[row, col] if n_rows > 1 else axes[col])

plt.tight_layout()
plt.show()








plt.figure(figsize=(8, 4))
sns.histplot(df['track_popularity'], kde=True, bins=30, edgecolor='black', alpha=0.7)
plt.title('Distribution of Track Popularity')
plt.xlabel('Track Popularity')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.7)
plt.show()








plt.figure(figsize=(8, 4))
genre_popularity = df.groupby('playlist_genre')['track_popularity'].mean().sort_values(ascending=False)
sns.barplot(x=genre_popularity.index, y=genre_popularity.values, palette='crest')
plt.title('Average Track Popularity by Genre')
plt.xlabel('Playlist Genre')
plt.ylabel('Average Popularity')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.7)
plt.show()








plt.figure(figsize=(14, 6))
subgenre_popularity = df.groupby('playlist_subgenre')['track_popularity'].mean().sort_values(ascending=False).head(20)
sns.barplot(x=subgenre_popularity.index, y=subgenre_popularity.values, palette='crest')
plt.title('Top 20 Subgenres by Average Popularity')
plt.xlabel('Playlist Subgenre')
plt.ylabel('Average Popularity')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.7)
plt.show()


top_subgenres_data = df[df['playlist_subgenre'].isin(subgenre_popularity.index)]
plt.figure(figsize=(14, 6))
sns.boxplot(data=top_subgenres_data, x='playlist_subgenre', y='track_popularity', palette='crest')
plt.title('Popularity Distribution Across Top Subgenres')
plt.xlabel('Subgenre')
plt.ylabel('Track Popularity')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.7)
plt.show()








corr_matrix = df[df_num_cols].corr()

plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='BrBG', cbar=True, square=True, linewidths=0.5, linecolor='black')
plt.title('Correlation Matrix of Numerical Features')
plt.xticks(rotation=45)
plt.show()








from sklearn.preprocessing import MinMaxScaler

music_features = ['danceability', 'energy', 'valence', 
                  'duration_ms', 'speechiness', 
                  'acousticness', 'instrumentalness', 
                  'liveness', 'track_popularity']

avg_features_by_year = df.groupby('year')[music_features].mean()

scaler = MinMaxScaler()
normalized_avg_features = pd.DataFrame(scaler.fit_transform(avg_features_by_year), 
                                       columns=music_features, 
                                       index=avg_features_by_year.index)

normalized_avg_features.reset_index(inplace=True)
melted_data = normalized_avg_features.melt(id_vars='year', var_name='feature', value_name='normalized_value')

pio.templates.default = "seaborn"
fig = px.line(melted_data, x='year', y='normalized_value', color='feature',
              markers=True, title='Trends of Normalized Musical Features Over Years')

fig.update_layout(xaxis_title='Year',
                  yaxis_title='Normalized Average Value',
                  legend_title='Features')

fig.show()








top_genres = df['playlist_genre'].value_counts().index
filtered_genres = df[df['playlist_genre'].isin(top_genres)]

plt.figure(figsize=(8, 4))
sns.boxplot(data=filtered_genres, x='playlist_genre', y='danceability', palette='crest')
plt.title('Danceability Distribution Across Genres')
plt.xlabel('Genre')
plt.ylabel('Danceability')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()
plt.show()





plt.figure(figsize=(8, 4))
sns.boxplot(data=df, x='playlist_genre', y='duration_ms', palette='crest')
plt.title('Duration Distribution by Playlist Genre')
plt.xlabel('Playlist Genre')
plt.ylabel('Duration (milliseconds)')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()
plt.show()








music_features = ['danceability', 'energy', 'valence', 'tempo', 
                  'duration_ms', 'speechiness', 
                  'acousticness', 'loudness', 'instrumentalness', 'liveness']

plt.figure(figsize=(16, 24))
for i, feature in enumerate(music_features, 1):
    plt.subplot(5, 2, i)
    sns.regplot(data=df, x=feature, y='track_popularity', 
                scatter_kws={'alpha': 0.3}, line_kws={'color': 'red'})
    plt.title(f'Relationship Between {feature} and Popularity')
    plt.xlabel(feature)
    plt.ylabel('Popularity')
    plt.grid(axis='both', alpha=0.7)
plt.tight_layout()
plt.show()






plt.figure(figsize=(16, 24))
selected_columns = ['energy', 'danceability', 'speechiness', 'instrumentalness', 'playlist_genre']
sns.pairplot(df[selected_columns], hue='playlist_genre', palette='Accent')
plt.title('The relationships across different genres')
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()
plt.show()








plt.figure(figsize=(8, 4))
sns.countplot(x='key', data=df, palette='crest', order=sorted(df['key'].unique()))
plt.title('Distribution of Musical Keys')
plt.xlabel('Key (0 = C, 1 = C#/Db, etc.)')
plt.ylabel('Count')
plt.grid(axis='y', alpha=0.7)
plt.show()





plt.figure(figsize=(8, 4))
sns.countplot(x='mode', data=df, palette='crest')
plt.title('Distribution of Modes (Major/Minor)')
plt.xlabel('Mode (0 = Minor, 1 = Major)')
plt.ylabel('Count')
plt.xticks(ticks=[0, 1], labels=['Minor', 'Major'])
plt.grid(axis='y', alpha=0.7)
plt.show()

















def preprocess_data(data):
    feature_columns = data.select_dtypes(include=['float64', 'int64']).columns
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(data[feature_columns])

    if 'genre' in data.columns:
        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
        genre_encoded = encoder.fit_transform(data[['genre']])
        processed_features = np.hstack([scaled_features, genre_encoded])
    else:
        processed_features = scaled_features

    return processed_features


processed_features = preprocess_data(df)








def recommend_songs(song_name, data, processed_features, n_recommendations=5):
    if song_name not in data['track_name'].values:
        return f"Песня '{song_name}' не найдена. Проверьте правильность названия."

    song_index = data[data['track_name'] == song_name].index[0]
    song_features = processed_features[song_index].reshape(1, -1)

    similarity_scores = cosine_similarity(song_features, processed_features).flatten()

    data['similarity'] = similarity_scores
    
    recommendations = data[data['track_name'] != song_name].sort_values(by='similarity', ascending=False)
    recommendations = recommendations.drop_duplicates(subset=['track_name', 'track_artist'])
    return recommendations[['track_name', 'track_artist', 'similarity']].head(n_recommendations)





song_to_recommend = "Выпускной (Медлячок)"
recommended_songs = recommend_songs(song_to_recommend, df, processed_features)

if isinstance(recommended_songs, str):
    print(recommended_songs)
else:
    print(f"Песни, похожие на: {song_to_recommend}, автора: {df[df.track_name == song_to_recommend]['track_artist'].head(1).item()}")
    print(recommended_songs)








def recommend_songs_with_clustering(song_name, data, processed_features, n_recommendations=5, n_clusters=10):
    if song_name not in data['track_name'].values:
        return f"Песня '{song_name}' не найдена в данных. Проверьте правильность названия."

    data = data.reset_index(drop=True)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    data['cluster'] = kmeans.fit_predict(processed_features)

    song_cluster = data[data['track_name'] == song_name]['cluster'].iloc[0]

    cluster_songs = data[data['cluster'] == song_cluster]
    cluster_indices = cluster_songs.index

    cluster_features = processed_features[cluster_indices]

    nbrs = NearestNeighbors(n_neighbors=min(n_recommendations + 1, len(cluster_indices))).fit(cluster_features)
    song_index = data[data['track_name'] == song_name].index[0]
    song_features = processed_features[song_index].reshape(1, -1)

    distances, indices = nbrs.kneighbors(song_features)

    recommendations_indices = cluster_indices[indices[0][1:]]
    recommendations = data.loc[recommendations_indices]

    return recommendations[['track_name', 'track_artist', 'cluster']]




def plot_clusters(data, processed_features, n_clusters=10):
    data = data.reset_index(drop=True)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(processed_features)

    pca = PCA(n_components=2)
    pca_features = pca.fit_transform(processed_features)

    plt.figure(figsize=(10, 6))
    scatter = plt.scatter(pca_features[:, 0], pca_features[:, 1], c=clusters, cmap='tab10', alpha=0.7)
    plt.colorbar(scatter, label='Cluster Label')
    plt.title('Визуализация кластеров с помощью PCA')
    plt.xlabel('PCA Feature 1')
    plt.ylabel('PCA Feature 2')
    plt.show()






song_to_recommend = "Выпускной (Медлячок)"
recommended_songs_cluster = recommend_songs_with_clustering(song_to_recommend, df, processed_features)

if isinstance(recommended_songs_cluster, str):
    print(recommended_songs_cluster)
else:
    print(f"Песни, похожие на: {song_to_recommend}, автора: {df[df.track_name == song_to_recommend]['track_artist'].head(1).item()}")
    print(recommended_songs_cluster)



plot_clusters(df, processed_features)







import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity

# Загружаем данные
df = pd.read_csv('/mnt/data/spotify_songs.csv')

# Выбираем интересующие признаки для модели
features = ['tempo', 'loudness', 'acousticness', 'valence', 'duration_ms', 'speechiness']
X = df[features].values

# Стандартизация данных
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Преобразуем в тензоры PyTorch
X_tensor = torch.tensor(X_scaled, dtype=torch.float32)

# Определяем архитектуру автоэнкодера
class Autoencoder(nn.Module):
    def __init__(self, input_dim, encoding_dim):
        super(Autoencoder, self).__init__()
        
        # Сжимаем входные данные
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, encoding_dim)
        )
        
        # Восстанавливаем данные
        self.decoder = nn.Sequential(
            nn.Linear(encoding_dim, 128),
            nn.ReLU(),
            nn.Linear(128, input_dim),
            nn.Sigmoid()  # Для восстановления значений в диапазоне [0, 1]
        )
        
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# Параметры модели
input_dim = X_tensor.shape[1]
encoding_dim = 64  # Размер скрытого представления

# Создаем модель
model = Autoencoder(input_dim=input_dim, encoding_dim=encoding_dim)

# Определяем функцию потерь и оптимизатор
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Обучение модели
epochs = 50
for epoch in range(epochs):
    model.train()
    
    # Прямой проход
    output = model(X_tensor)
    
    # Вычисляем потерю
    loss = criterion(output, X_tensor)
    
    # Обратный проход и обновление весов
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

# Извлекаем скрытые признаки
model.eval()
encoded_X = model.encoder(X_tensor).detach().numpy()

# Расчет косинусного сходства между скрытыми признаками
similarity_matrix = cosine_similarity(encoded_X)

# Функция для рекомендаций
def recommend_tracks_autoencoder(track_index, similarity_matrix, df, top_n=5):
    similar_tracks = similarity_matrix[track_index].argsort()[-top_n-1:-1][::-1]
    
    recommendations = []
    for idx in similar_tracks:
        recommendations.append({
            'track_name': df.iloc[idx]['track_name'],
            'track_artist': df.iloc[idx]['track_artist'],
            'track_popularity': df.iloc[idx]['track_popularity'],
            'track_album_name': df.iloc[idx]['track_album_name'],
        })
    return recommendations

# Пример: Рекомендации для первого трека
track_index = 0
recommended_tracks = recommend_tracks_autoencoder(track_index, similarity_matrix, df)

# Выводим рекомендованные треки
for track in recommended_tracks:
    print(f"Track: {track['track_name']} by {track['track_artist']}, Popularity: {track['track_popularity']}")

